{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "INFORMATION\n",
    "\n",
    "Date: 2019/12/29\n",
    "OS: Windows 10\n",
    "\n",
    "Tensorflow-gpu: v1.13.1\n",
    "cython: 0.29.14\n",
    "context: 0.6.0.post1\n",
    "pillow: 6.2.1\n",
    "lxml: 4.4.2\n",
    "matplotlib: 3.1.2\n",
    "opencv-python: 4.1.2.30\n",
    "jupyter: 1.0.0\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set environment variable for object detection\n",
    "<pre><font size=4>\n",
    "For setting up the path so that the OS can this API, we set a PYTHONPATH for it\n",
    "<font size=3>\n",
    "    <span style='background:#E8E8E8'>set PYTHONPATH=<b>&#60;tensorflow&#62;</b>\\models;<b>&#60;tensorflow&#62;</b>\\models\\research;<b>&#60;tensorflow&#62;</b>\\models\\research\\slim</span>\n",
    "\n",
    "<b>Note:</b> The <b>&#60;tensorflow&#62;</b> is the directory where <i>\\models</i> is located\n",
    "      There's \";\" between each path, do not forget them\n",
    "      This will create a temporary <b>environment variable</b>, so you have to run this <font color=\"red\">EACH TIME</font> opening <b>Prompt</b>\n",
    "      You may head to <b>environment variable</b> for creating a permanent one\n",
    "      By <span style='background:#E8E8E8'>echo %PYTHONPATH%</span>, you can see if you set it right\n",
    "</font>\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup object detection API\n",
    "<pre><font size=4>\n",
    "Head to <i><b>&#60;tensorflow&#62;\\models\\research</b></i> in virtual environment you've created by <span style='background:#E8E8E8'>cd</span> command\n",
    "\n",
    "Paste all the command below and run it\n",
    "<table align=\"left\"><tr><td><font size = 3>\n",
    "protoc --python_out=. .\\object_detection\\protos\\anchor_generator.proto .\\object_detection\\protos\\argmax_matcher.proto .\\object_detection\\protos\\bipartite_matcher.proto .\\object_detection\\protos\\box_coder.proto .\\object_detection\\protos\\box_predictor.proto .\\object_detection\\protos\\eval.proto .\\object_detection\\protos\\faster_rcnn.proto .\\object_detection\\protos\\faster_rcnn_box_coder.proto .\\object_detection\\protos\\grid_anchor_generator.proto .\\object_detection\\protos\\hyperparams.proto .\\object_detection\\protos\\image_resizer.proto .\\object_detection\\protos\\input_reader.proto .\\object_detection\\protos\\losses.proto .\\object_detection\\protos\\matcher.proto .\\object_detection\\protos\\mean_stddev_box_coder.proto .\\object_detection\\protos\\model.proto .\\object_detection\\protos\\optimizer.proto .\\object_detection\\protos\\pipeline.proto .\\object_detection\\protos\\post_processing.proto .\\object_detection\\protos\\preprocessor.proto .\\object_detection\\protos\\region_similarity_calculator.proto .\\object_detection\\protos\\square_box_coder.proto .\\object_detection\\protos\\ssd.proto .\\object_detection\\protos\\ssd_anchor_generator.proto .\\object_detection\\protos\\string_int_label_map.proto .\\object_detection\\protos\\train.proto .\\object_detection\\protos\\keypoint_box_coder.proto .\\object_detection\\protos\\multiscale_anchor_generator.proto .\\object_detection\\protos\\graph_rewriter.proto .\\object_detection\\protos\\calibration.proto .\\object_detection\\protos\\flexible_grid_anchor_generator.proto\n",
    "</font></td></tr></table>\n",
    "</font></pre>\n",
    "<pre><font size=4>\n",
    "<font size=3><b>Note:</b> Sometimes your protobuf module might not work properly, reinstall it again by <span style='background:#E8E8E8'>conda install -c anaconda protobuf</span>\n",
    "</font>\n",
    "And build this API by typing\n",
    "\n",
    "    <font size=3><span style='background:#E8E8E8'>python setup.py build</span></font>\n",
    "    <font size=3><span style='background:#E8E8E8'>python setup.py install</span></font>\n",
    "<font size=3>\n",
    "<b>Note:</b> Your might have to run lines above each time you change something of the object detection module\n",
    "</font>\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the pre-trained model you'd like to apply\n",
    "<pre><font size=4>\n",
    "You can find pre-trained models on Tensorflow model zoo\n",
    "\n",
    "    <a href=\"https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md\">&#9658; Tensorflow detection model zoo</a>\n",
    "\n",
    "Download the model that you want and extract it into\n",
    "\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection</b></i>\n",
    "\n",
    "And then copy the following .config file from\n",
    "\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\samples\\configs</b></i>\n",
    "\n",
    "and put it into\n",
    "\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\training</b></i>\n",
    "<font size=3>\n",
    "<b>Note:</b> Here we are going to use <b>faster_rcnn_inception_v2_coco_2018_01_28</b> model\n",
    "      so we download the model zipped in .tar.gz file and extract it to <i><b>\\object_detection</b></i>\n",
    "      then copy <b>faster_rcnn_inception_v2_coco.config</b> and paste into <i><b>\\object_detection\\training</b></i>\n",
    "</font>\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for the images\n",
    "<pre><font size=4>\n",
    "In the API, you need to separate training and validation set by yourself and you must have them\n",
    "\n",
    "So I wrote copy_files_to_train_and_test.ipynb and put it in <a href=\"https://github.com/bboyleonp666/ObjectDetection/tree/master/tutorial\">my tutorial</a>\n",
    "\n",
    "You can modify it by change the source directory of you images and annotations\n",
    "\n",
    "But the target folder must be under the directories below separately\n",
    "\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\images\\train</b></i>\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\images\\test</b></i>\n",
    "<font size=3>\n",
    "<b>Note:</b> I extract train_cdc.zip to <i>..\\models\\research\\object_detection\\images</i> and put <b>copy_files_to_train_and_test.ipynb</b> in it\n",
    "      By doing so, you don't have to change anything and just run everything will be done automatically\n",
    "      <b>copy_files_to_train_and_test.ipynb</b> is put in <a href=\"https://github.com/bboyleonp666/ObjectDetection/tree/master/tutorial\">my tutorial</a>\n",
    "</font>\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer xml to record\n",
    "---\n",
    "## xml to csv\n",
    "<pre><font size=4>\n",
    "Under <i><b>&#60;tensorflow&#62;</b>\\models\\research\\object_detection</i> run\n",
    "\n",
    "    <font size=3><span style='background:#E8E8E8'>python xml_to_csv.py</span></font>\n",
    "\n",
    "which will transfer the xml files in \\images to csv files for training and validation\n",
    "<font size=3>\n",
    "<b>Note:</b> If you use the <a href=\"https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10\">source</a> ver, instead of mine, just need to change xml_to_csv a little bit like below\n",
    "      Since the our xml file structure is kind of different from the xml created by <b>LabelImg</b>\n",
    "</font>\n",
    "</font></pre>\n",
    "<img src=\"modify_xml_to_csv.png\" alt=\"Modify xml_to_csv.py\" style=\"width: 800px;\">\n",
    "\n",
    "---\n",
    "<pre>\n",
    "</pre>\n",
    "<font size=6 color=\"orange\"><b>NOTE:</b></font>\n",
    "<pre><font size=4 color=\"gray\">\n",
    "For the parts before Generate TFrecord, you can skip them by using the code that I wrote \n",
    "\n",
    "Which is put <a href=\"https://github.com/bboyleonp666/ObjectDetection/tree/master/tutorial\">here</a> named <b>create_pbtxt_and_modify_generate_tfrecord.ipynb</b>\n",
    "\n",
    "You can just put it in\n",
    "\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\images</b></i>\n",
    "    \n",
    "And run with any change\n",
    "\n",
    "Or somewhere but with the input path changing\n",
    "</font></pre>\n",
    "\n",
    "---\n",
    "## create label map\n",
    "<pre><font size=4>\n",
    "Label map format is shown below\n",
    "\n",
    "And should be saved under <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\training</b></i> folder\n",
    "<font size=3>\n",
    "item {\n",
    "    id: 1\n",
    "    name: 'bucket'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: 2\n",
    "    name: 'toilet'\n",
    "}\n",
    "</font>\n",
    "<font size=3>\n",
    "<b>Note:</b> You have to set them one by one and give them id from 1 to n\n",
    "      0 is preserved for background variable in API, so you <font color=\"red\">must not set <b>id: 0</b></font>\n",
    "</font>\n",
    "</font></pre>\n",
    "---\n",
    "## csv to record\n",
    "<pre><font size=4>\n",
    "We have to modify the <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\generate_tfrecord.py</b></i>\n",
    "\n",
    "with the labels named for objects like below\n",
    "<font size=3>\n",
    "# Assume that we got dog and cat as our labels\n",
    "def class_text_to_int(row_label):\n",
    "    if row_label == 'dog':\n",
    "        return 1\n",
    "    elif row_label == 'cat':\n",
    "        return 2\n",
    "    else:\n",
    "        None\n",
    "</font>\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate TFrecord\n",
    "<pre><font size=4>\n",
    "<span style='background:#E8E8E8'>cd</span> into <i><b>&#60;tensorflow&#62;\\models\\research</b></i> and run\n",
    "<font size=3>\n",
    "    <span style='background:#E8E8E8'>python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.record</span>\n",
    "    <span style='background:#E8E8E8'>python generate_tfrecord.py --csv_input=images\\test_labels.csv --image_dir=images\\test --output_path=test.record</span>\n",
    "</font>\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust some detail in config\n",
    "<pre><font size=4>\n",
    "The .config file has some lines that we have to adjust ourselves\n",
    "\n",
    "which is shown below and marked in colors\n",
    "<font color=\"red\" size=3>\n",
    "<b>NOTE:</b> The path below should all be \"/\" instead of \"\\\"\n",
    "      If you copy and paste the path, remember to correct it\n",
    "</font>\n",
    "<font size=3>\n",
    "# SSD with Inception v2 configuration for MSCOCO Dataset.\n",
    "# Users should configure the fine_tune_checkpoint field in the train config as\n",
    "# well as the label_map_path and input_path fields in the train_input_reader and\n",
    "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
    "# should be configured.\n",
    "\n",
    "model {\n",
    "    ssd {\n",
    "        <span style=\"background:lightyellow\">num_classes: 1    <font color=\"red\"># Set this to the number of different label classes (which is 13 in our case)</font></span>\n",
    "        box_coder {\n",
    "            faster_rcnn_box_coder {\n",
    "                y_scale: 10.0\n",
    "                x_scale: 10.0\n",
    "                height_scale: 5.0\n",
    "                width_scale: 5.0\n",
    "            }\n",
    "        }\n",
    "        matcher {\n",
    "            argmax_matcher {\n",
    "                matched_threshold: 0.5\n",
    "                unmatched_threshold: 0.5\n",
    "                ignore_thresholds: false\n",
    "                negatives_lower_than_unmatched: true\n",
    "                force_match_for_each_row: true\n",
    "            }\n",
    "        }\n",
    "        similarity_calculator {\n",
    "            iou_similarity {\n",
    "            }\n",
    "        }\n",
    "        anchor_generator {\n",
    "            ssd_anchor_generator {\n",
    "                num_layers: 6\n",
    "                min_scale: 0.2\n",
    "                max_scale: 0.95\n",
    "                aspect_ratios: 1.0\n",
    "                aspect_ratios: 2.0\n",
    "                aspect_ratios: 0.5\n",
    "                aspect_ratios: 3.0\n",
    "                aspect_ratios: 0.3333\n",
    "                reduce_boxes_in_lowest_layer: true\n",
    "            }\n",
    "        }\n",
    "        image_resizer {\n",
    "            fixed_shape_resizer {\n",
    "                height: 300\n",
    "                width: 300\n",
    "            }\n",
    "        }\n",
    "        box_predictor {\n",
    "            convolutional_box_predictor {\n",
    "                min_depth: 0\n",
    "                max_depth: 0\n",
    "                num_layers_before_predictor: 0\n",
    "                use_dropout: false\n",
    "                dropout_keep_probability: 0.8\n",
    "                kernel_size: 3\n",
    "                box_code_size: 4\n",
    "                apply_sigmoid_to_scores: false\n",
    "                conv_hyperparams {\n",
    "                activation: RELU_6,\n",
    "                regularizer {\n",
    "                    l2_regularizer {\n",
    "                        weight: 0.00004\n",
    "                    }\n",
    "                }\n",
    "                initializer {\n",
    "                        truncated_normal_initializer {\n",
    "                            stddev: 0.03\n",
    "                            mean: 0.0\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        feature_extractor {\n",
    "            <span style=\"background:lightyellow\">type: 'ssd_inception_v2'    <font color=\"red\"># Set to the name of your chosen pre-trained model</font></span>\n",
    "            min_depth: 16\n",
    "            depth_multiplier: 1.0\n",
    "            conv_hyperparams {\n",
    "                activation: RELU_6,\n",
    "                regularizer {\n",
    "                    l2_regularizer {\n",
    "                        weight: 0.00004\n",
    "                    }\n",
    "                }\n",
    "                initializer {\n",
    "                    truncated_normal_initializer {\n",
    "                        stddev: 0.03\n",
    "                        mean: 0.0\n",
    "                    }\n",
    "                }\n",
    "                batch_norm {\n",
    "                    train: true,\n",
    "                    scale: true,\n",
    "                    center: true,\n",
    "                    decay: 0.9997,\n",
    "                    epsilon: 0.001,\n",
    "                }\n",
    "            }\n",
    "            override_base_feature_extractor_hyperparams: true\n",
    "        }\n",
    "        loss {\n",
    "            classification_loss {\n",
    "                weighted_sigmoid {\n",
    "                }\n",
    "            }\n",
    "            localization_loss {\n",
    "                weighted_smooth_l1 {\n",
    "                }\n",
    "            }\n",
    "            hard_example_miner {\n",
    "                num_hard_examples: 3000\n",
    "                iou_threshold: 0.99\n",
    "                loss_type: CLASSIFICATION\n",
    "                max_negatives_per_positive: 3\n",
    "                min_negatives_per_image: 0\n",
    "            }\n",
    "            classification_weight: 1.0\n",
    "            localization_weight: 1.0\n",
    "        }\n",
    "        normalize_loss_by_num_matches: true\n",
    "        post_processing {\n",
    "            batch_non_max_suppression {\n",
    "                score_threshold: 1e-8\n",
    "                iou_threshold: 0.6\n",
    "                max_detections_per_class: 100\n",
    "                max_total_detections: 100\n",
    "            }\n",
    "            score_converter: SIGMOID\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "train_config: {\n",
    "    <span style=\"background:lightyellow\">batch_size: 12    <font color=\"red\"># Increase/Decrease this value depending on the available memory (Higher values require more)</font></span>\n",
    "    <font color=\"red\" size=4><b># The fact is, if you change it, it will fail to train</b></font>\n",
    "    optimizer {\n",
    "        rms_prop_optimizer: {\n",
    "            learning_rate: {\n",
    "                exponential_decay_learning_rate {\n",
    "                    initial_learning_rate: 0.004\n",
    "                    decay_steps: 800720\n",
    "                    decay_factor: 0.95\n",
    "                }\n",
    "            }\n",
    "            momentum_optimizer_value: 0.9\n",
    "            decay: 0.9\n",
    "            epsilon: 1.0\n",
    "        }\n",
    "    }\n",
    "    <span style=\"background:lightyellow\">fine_tune_checkpoint: \"pre-trained-model/model.ckpt\"    <font color=\"red\"># Path to pre-trained model (which you paste in \\object_detedtion)</font></span>\n",
    "    from_detection_checkpoint: true\n",
    "    # Note: The below line limits the training process to 200K steps, which we\n",
    "    # empirically found to be sufficient enough to train the pets dataset. This\n",
    "    # effectively bypasses the learning rate schedule (the learning rate will\n",
    "    # never decay). Remove the below line to train indefinitely.\n",
    "    num_steps: 200000    <font color=\"red\"># Here you don't have to change even if it's high, we will explain in next tutorial</font>\n",
    "    data_augmentation_options {\n",
    "        random_horizontal_flip {\n",
    "        }\n",
    "    }\n",
    "    data_augmentation_options {\n",
    "        ssd_random_crop {\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "train_input_reader: {\n",
    "    tf_record_input_reader {\n",
    "        <span style=\"background:lightyellow\">input_path: \"annotations/train.record\"    <font color=\"red\"># Path to training TFRecord file</font></span>\n",
    "    }\n",
    "    <span style=\"background:lightyellow\">label_map_path: \"annotations/label_map.pbtxt\"    <font color=\"red\"># Path to label map file</font></span>\n",
    "}\n",
    "\n",
    "eval_config: {\n",
    "    <span style=\"background:lightyellow\">num_examples: 8000    <font color=\"red\"># How many test examples are there (534 in our case)</font></span>\n",
    "    # Note: The below line limits the evaluation process to 10 evaluations.\n",
    "    # Remove the below line to evaluate indefinitely.\n",
    "    max_evals: 10\n",
    "}\n",
    "\n",
    "eval_input_reader: {\n",
    "    tf_record_input_reader {\n",
    "        <span style=\"background:lightyellow\">input_path: \"annotations/test.record\"    <font color=\"red\"># Path to testing TFRecord</font></span>\n",
    "    }\n",
    "    <span style=\"background:lightyellow\">label_map_path: \"annotations/label_map.pbtxt\"    <font color=\"red\"># Path to label map file</font></span>\n",
    "    shuffle: false\n",
    "    num_readers: 1\n",
    "}\n",
    "</font>\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy train.py\n",
    "<pre><font size=4>\n",
    "For training, we need train.py file which is put in\n",
    "\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection\\legacy</b></i>\n",
    "    \n",
    "Copy it and paste in\n",
    "\n",
    "    <i><b>&#60;tensorflow&#62;\\models\\research\\object_detection</b></i>\n",
    "\n",
    "</font></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6><div align=\"center\"><i>Congratulations!!!</i></div></font>\n",
    "<br>\n",
    "<font size=6><div align=\"center\"><i>You can train your model for now</i></div></font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
