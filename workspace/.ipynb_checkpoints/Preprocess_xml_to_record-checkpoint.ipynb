{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation\n",
    "### Transfer xml to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tutorial:\n",
    "# https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\n",
    "\n",
    "'''\n",
    "Tensorflow GPU version: 2.0.0\n",
    "CUDA version: 10.0\n",
    "OS system: Windows 10\n",
    "\n",
    "Notice: the tutorial tensorflow version is 1.9\n",
    "'''\n",
    "\n",
    "# packages for xml to csv\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_to_csv(input_path=None, output_csv_path=None):\n",
    "    # if input variables are not defined, then put them in current working directory and input_path separately\n",
    "    if(input_path==None):\n",
    "        input_path = os.getcwd()\n",
    "    if(output_csv_path==None):\n",
    "        output_csv_path = os.getcwd()\n",
    "    \n",
    "    xml_list = []\n",
    "    for xml_file in os.listdir(input_path):\n",
    "        xml_file_path = os.path.join(input_path, xml_file)\n",
    "        \n",
    "        # parse the xml file\n",
    "        tree = ET.parse(xml_file_path) \n",
    "        root = tree.getroot()\n",
    "\n",
    "        # root.findall('object'): find the <object> tag which can lead to the number of labeled items\n",
    "        # better open the .xml file to check the tags and infos inside\n",
    "        for member in root.findall('object'):\n",
    "            value = (root.find('filename').text,      # info of image file name\n",
    "                     int(root.find('size')[0].text),  # width of the image\n",
    "                     int(root.find('size')[1].text),  # height of the image\n",
    "                                                      # depth of the image can be found by -- int(root.find('size')[2].text)\n",
    "                     member[0].text,                  # the first tag under object tag which is the label\n",
    "                     int(member[1][0].text),          # the label box xmin\n",
    "                     int(member[1][1].text),          # the label box ymin\n",
    "                     int(member[1][2].text),          # the label box xmax\n",
    "                     int(member[1][3].text),          # the label box ymax\n",
    "                     )\n",
    "            xml_list.append(value)\n",
    "\n",
    "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
    "    \n",
    "    # write the data into csv\n",
    "    csv_file = os.path.join(output_csv_path, \"label.csv\")\n",
    "    xml_df.to_csv(csv_file, index=False)\n",
    "\n",
    "    print('Successfully converted xml to csv: {}'.format(output_csv_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer csv to TFrecord file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages for csv to record\n",
    "import os\n",
    "import io\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "\n",
    "# sys.path is a list with paths to modules\n",
    "# sys.path.append can add a new path while using python, but the new path will disappear after python is closed\n",
    "\n",
    "    # sys.path.append(\"../../models/research\")\n",
    "\n",
    "sys.path.append(\"C:/Users/user/Tensorflow/models/research\")\n",
    "from PIL import Image\n",
    "from object_detection.utils import dataset_util\n",
    "from collections import namedtuple, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_dict(dataframe):\n",
    "    labels = dataframe['class']\n",
    "\n",
    "    embedding_list = []\n",
    "    for i, label in enumerate(set(labels)):\n",
    "        embed = [i, label]\n",
    "        embedding_list.append(embed)\n",
    "    return embedding_list\n",
    "\n",
    "def class_text_to_int(label, embedding):\n",
    "    for INDEX, CLASS in embedding:\n",
    "        if label == CLASS:\n",
    "            return INDEX\n",
    "        else:\n",
    "            None\n",
    "            \n",
    "def split_train_valid(files, valid_ratio=0.2):\n",
    "    random.seed(\"HoHoHo, Merry Christmas\")\n",
    "    valid_files = random.sample(files, int(len(files)*valid_ratio))\n",
    "    train_files = set(files) - set(valid_files)\n",
    "    return train_files, valid_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_example(file, path, group, embedding):\n",
    "    # tf.io.gfile.GFile: like the open() which is built-in python but faster\n",
    "    # 'rb': read data in bytes\n",
    "    # 'r': read data in string\n",
    "    with tf.io.gfile.GFile(os.path.join(path, file), 'rb') as file_id:\n",
    "        encoded_jpg = file_id.read()\n",
    "\n",
    "    encoded_jpg_io = io.BytesIO(encoded_jpg)   # encode jpg file by io.BytesIO\n",
    "    img = Image.open(encoded_jpg_io)           # read the encoded jpg file\n",
    "    width, height = img.size                   # save the size(width and height) of the jpg file\n",
    "    filename = file.encode('utf8')              # encode file name by utf-8\n",
    "\n",
    "    image_format = b'jpg'                      # check the format is matching the images\n",
    "    xmins = []\n",
    "    xmaxs = []\n",
    "    ymins = []\n",
    "    ymaxs = []\n",
    "    classes_text = []\n",
    "    classes = []\n",
    "\n",
    "    # index for data info stored in csv file\n",
    "    # -----------\n",
    "    # 0, filename\n",
    "    # 1, width\n",
    "    # 2, height\n",
    "    # 3, class\n",
    "    # 4, xmin\n",
    "    # 5, ymin\n",
    "    # 6, xmax\n",
    "    # 7, ymax\n",
    "    # -----------\n",
    "\n",
    "    value_df = group.get_group(file)   # get the data under current group in the loop\n",
    "    for object_info in value_df.values:\n",
    "        classes_text.append(object_info[3].encode('utf8')) # for save label type b'label', where 'b' stands for binary data\n",
    "        classes.append(class_text_to_int(object_info[3], embedding))  # class text to integer, namely, embedding or categorize\n",
    "\n",
    "        xmins.append(object_info[4] / width)\n",
    "        ymins.append(object_info[5] / width)\n",
    "        xmaxs.append(object_info[6] / height)\n",
    "        ymaxs.append(object_info[7] / height)\n",
    "\n",
    "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'image/height': dataset_util.int64_feature(height),\n",
    "        'image/width': dataset_util.int64_feature(width),\n",
    "        'image/filename': dataset_util.bytes_feature(filename),\n",
    "        'image/source_id': dataset_util.bytes_feature(filename),\n",
    "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
    "        'image/format': dataset_util.bytes_feature(image_format),\n",
    "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
    "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
    "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
    "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
    "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
    "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
    "    }))\n",
    "\n",
    "    return tf_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create label map\n",
    "<pre>\n",
    "<font size = 4>label map is like the format below</font>\n",
    "<b>\n",
    "item {\n",
    "    id: 1\n",
    "    name: 'cat'\n",
    "}\n",
    "\n",
    "item {\n",
    "    id: 2\n",
    "    name: 'dog'\n",
    "}\n",
    "</b>\n",
    "<font size = 4>which will be used for training and object detection so we must create them</font>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_map(embedding):\n",
    "    with open(\"label.pbtext\", \"w\") as label_map:    \n",
    "        for ID, NAME in embedding:\n",
    "            line0 = \"item {\\n\"\n",
    "            line1 = \"    id: {}\\n\".format(ID)\n",
    "            line2 = \"    name: '{}'\\n\".format(NAME)\n",
    "            line3 = \"}\\n\"\n",
    "\n",
    "            print(line0 + line1 + line2 + line3, file=label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    xml_to_csv(train_path_annotation, file_path)                 # transfer xml to csv file\n",
    "    img_path = train_path_img                                    # path for images(training)\n",
    "    output_path = os.path.join(os.getcwd(), \"output_files\")      # path for output as .record file\n",
    "    csvfile = os.path.join(file_path, \"label.csv\")               # path for csv file\n",
    "    examples = pd.read_csv(csvfile)                              # read csv file which contains the info for labels \n",
    "    embedding = label_dict(examples)                             # create a embedding list for create_tf_example()\n",
    "    create_label_map(embedding)                                  # create label map for training as .pbtext file\n",
    "    \n",
    "    ### print out label number created for modifying .config\n",
    "    print(\"\\nTotal label number: {}\".format(len(embedding)))       \n",
    "    print(\"-----\")\n",
    "    for idx, label in embedding:\n",
    "        print(\"{}: {}\".format(idx, label))\n",
    "    \n",
    "    ### print out the frequence table for labels\n",
    "    print(\"\\nFrequence Table\")\n",
    "    print(\"-----\")\n",
    "    print(pd.value_counts(examples[\"class\"]))\n",
    "    \n",
    "    ### use TFRecordWriter to write TFRecord file\n",
    "    group = examples.groupby(\"filename\")                         # create tensorflow example by each jpg file\n",
    "    files = group.groups.keys()                                  # get file names from groupby data\n",
    "    train_files, valid_files = split_train_valid(files)          # separate train and validation images\n",
    "    \n",
    "    # train.record\n",
    "    writer = tf.io.TFRecordWriter(os.path.join(output_path, \"train.record\"))\n",
    "    for jpg in train_files:\n",
    "        tf_example = create_tf_example(jpg, img_path, group, embedding)\n",
    "        writer.write(tf_example.SerializeToString())             # serialize the output by package protobuf\n",
    "    writer.close()\n",
    "    \n",
    "    # valid.record\n",
    "    writer = tf.io.TFRecordWriter(os.path.join(output_path, \"valid.record\"))\n",
    "    for jpg in valid_files:\n",
    "        tf_example = create_tf_example(jpg, img_path, group, embedding)\n",
    "        writer.write(tf_example.SerializeToString())             # serialize the output by package protobuf\n",
    "    writer.close()\n",
    "    \n",
    "    print()\n",
    "    print('Successfully created the TFRecords: {}'.format(output_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mData\u001b[0m\n",
      "------\n",
      "Images: D:\\DeepLearning\\Project04_ContainerDetection\\images\n",
      "\n",
      "\u001b[1mTrain data and Test data\u001b[0m\n",
      "------\n",
      "Train: D:\\DeepLearning\\Project04_ContainerDetection\\images\\train_cdc\n",
      "Test: D:\\DeepLearning\\Project04_ContainerDetection\\images\\test_cdc\n",
      "\n",
      "\u001b[1mAnnotation and Images\u001b[0m\n",
      "------\n",
      "Train annotation: D:\\DeepLearning\\Project04_ContainerDetection\\images\\train_cdc\\train_annotations\n",
      "Train images: D:\\DeepLearning\\Project04_ContainerDetection\\images\\train_cdc\\train_images\n",
      "Test images: D:\\DeepLearning\\Project04_ContainerDetection\\images\\test_cdc\\test_images\n",
      "\n",
      "\u001b[1mSave output files\u001b[0m\n",
      "------\n",
      "Path for saving outputs: D:\\DeepLearning\\Project04_ContainerDetection\\workspace\\output_files\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "    PURPLE = '\\033[95m'\n",
    "    CYAN = '\\033[96m'\n",
    "    DARKCYAN = '\\033[36m'\n",
    "    BLUE = '\\033[94m'\n",
    "    GREEN = '\\033[92m'\n",
    "    YELLOW = '\\033[93m'\n",
    "    RED = '\\033[91m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "    END = '\\033[0m'\n",
    "\n",
    "# get image path\n",
    "project04_root = os.path.dirname(os.getcwd())\n",
    "img_path = os.path.join(project04_root, \"images\")\n",
    "print(color.BOLD + \"Data\" + color.END)\n",
    "print(\"------\")\n",
    "print(\"Images: {}\\n\".format(img_path))\n",
    "\n",
    "# get image path of train and test separately\n",
    "train_path = os.path.join(img_path, \"train_cdc\")\n",
    "test_path = os.path.join(img_path, \"test_cdc\")\n",
    "print(color.BOLD + \"Train data and Test data\" + color.END)\n",
    "print(\"------\")\n",
    "print(\"Train: {}\".format(train_path))\n",
    "print(\"Test: {}\\n\".format(test_path))\n",
    "\n",
    "\n",
    "# get path for annotation of train dataset\n",
    "train_path_annotation = os.path.join(train_path, \"train_annotations\")\n",
    "train_path_img = os.path.join(train_path, \"train_images\")\n",
    "test_path_img  = os.path.join(test_path, \"test_images\")\n",
    "print(color.BOLD + \"Annotation and Images\" + color.END)\n",
    "print(\"------\")\n",
    "print(\"Train annotation: {}\".format(train_path_annotation))\n",
    "print(\"Train images: {}\".format(train_path_img))\n",
    "print(\"Test images: {}\\n\".format(test_path_img))\n",
    "\n",
    "\n",
    "# output file path\n",
    "file_path = os.path.join(os.getcwd(), \"output_files\")\n",
    "print(color.BOLD + \"Save output files\" + color.END)\n",
    "print(\"------\")\n",
    "print(\"Path for saving outputs: {}\".format(file_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv: D:\\DeepLearning\\Project04_ContainerDetection\\workspace\\output_files\n",
      "\n",
      "Total label number: 13\n",
      "-----\n",
      "0: water_tower\n",
      "1: toilet\n",
      "2: tub\n",
      "3: tire\n",
      "4: bowl\n",
      "5: bottle\n",
      "6: bucket\n",
      "7: plastic_bag\n",
      "8: box\n",
      "9: washing_machine\n",
      "10: aquarium\n",
      "11: styrofoam\n",
      "12: plate\n",
      "\n",
      "Frequence Table\n",
      "-----\n",
      "bucket             2200\n",
      "tire               1357\n",
      "bowl               1115\n",
      "plastic_bag        1047\n",
      "bottle              650\n",
      "box                 558\n",
      "styrofoam           410\n",
      "plate               264\n",
      "water_tower         174\n",
      "tub                  55\n",
      "toilet               46\n",
      "aquarium             34\n",
      "washing_machine      25\n",
      "Name: class, dtype: int64\n",
      "\n",
      "Successfully created the TFRecords: D:\\DeepLearning\\Project04_ContainerDetection\\workspace\\output_files\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
